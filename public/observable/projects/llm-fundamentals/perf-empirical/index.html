<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="generator" content="Observable Framework v1.13.3">
<title>Empirical Performance | Project Writeup Sandbox</title>

<link rel="preload" as="style" href="../../../_import/astro-bridge-theme.21c55a64.css">
<link rel="preload" as="style" href="../../../_npm/katex@0.16.28/dist/katex.min.css">
<link rel="stylesheet" type="text/css" href="../../../_import/astro-bridge-theme.21c55a64.css">
<link rel="stylesheet" type="text/css" href="../../../_npm/katex@0.16.28/dist/katex.min.css">
<link rel="modulepreload" href="../../../_observablehq/client.cbf2d9f3.js">
<link rel="modulepreload" href="../../../_observablehq/runtime.e080113b.js">
<link rel="modulepreload" href="../../../_observablehq/stdlib.43270668.js">
<link rel="modulepreload" href="../../../_import/embed/perf-empirical.afc56bfd.js">
<link rel="modulepreload" href="../../../_observablehq/stdlib/tex.c79b643a.js">
<link rel="modulepreload" href="../../../_import/components/data-utils.e2caa41c.js">
<link rel="modulepreload" href="../../../_import/components/dom-utils.363530d4.js">
<link rel="modulepreload" href="../../../_import/components/perf-estimates.d771a94d.js">
<link rel="modulepreload" href="../../../_npm/@observablehq/plot@0.6.17/7c43807f.js">
<link rel="modulepreload" href="../../../_npm/d3@7.9.0/e324157d.js">
<link rel="modulepreload" href="../../../_npm/apache-arrow@21.1.0/63de76cd.js">
<link rel="modulepreload" href="../../../_npm/parquet-wasm@0.7.1/68d81b68.js">
<link rel="modulepreload" href="../../../_npm/katex@0.16.28/f76b8a99.js">
<link rel="modulepreload" href="../../../_npm/isoformat@0.2.1/18cbf477.js">
<link rel="modulepreload" href="../../../_npm/interval-tree-1d@1.0.4/53fe8176.js">
<link rel="modulepreload" href="../../../_npm/d3-array@3.2.4/e93ca09f.js">
<link rel="modulepreload" href="../../../_npm/d3-axis@3.0.0/0f2de24d.js">
<link rel="modulepreload" href="../../../_npm/d3-brush@3.0.0/65eb105b.js">
<link rel="modulepreload" href="../../../_npm/d3-chord@3.0.1/7ef8fb2e.js">
<link rel="modulepreload" href="../../../_npm/d3-color@3.1.0/aeb57b94.js">
<link rel="modulepreload" href="../../../_npm/d3-contour@4.0.2/1d2aed74.js">
<link rel="modulepreload" href="../../../_npm/d3-delaunay@6.0.4/5ced1d52.js">
<link rel="modulepreload" href="../../../_npm/d3-dispatch@3.0.1/9ba9c7f3.js">
<link rel="modulepreload" href="../../../_npm/d3-drag@3.0.0/4202580c.js">
<link rel="modulepreload" href="../../../_npm/d3-dsv@3.0.1/9cffc2bd.js">
<link rel="modulepreload" href="../../../_npm/d3-ease@3.0.1/cdd7e898.js">
<link rel="modulepreload" href="../../../_npm/d3-fetch@3.0.1/b4e2ad9a.js">
<link rel="modulepreload" href="../../../_npm/d3-force@3.0.0/5e804d15.js">
<link rel="modulepreload" href="../../../_npm/d3-format@3.1.2/3785bf2d.js">
<link rel="modulepreload" href="../../../_npm/d3-geo@3.1.1/40599fb3.js">
<link rel="modulepreload" href="../../../_npm/d3-hierarchy@3.1.2/e49e792c.js">
<link rel="modulepreload" href="../../../_npm/d3-interpolate@3.0.1/8d1e5425.js">
<link rel="modulepreload" href="../../../_npm/d3-path@3.1.0/20d3f133.js">
<link rel="modulepreload" href="../../../_npm/d3-polygon@3.0.1/7553081f.js">
<link rel="modulepreload" href="../../../_npm/d3-quadtree@3.0.1/0dfd751c.js">
<link rel="modulepreload" href="../../../_npm/d3-random@3.0.1/3c90ee06.js">
<link rel="modulepreload" href="../../../_npm/d3-scale@4.0.2/720b7f0a.js">
<link rel="modulepreload" href="../../../_npm/d3-scale-chromatic@3.1.0/ba24c2e7.js">
<link rel="modulepreload" href="../../../_npm/d3-selection@3.0.0/4d94e5b7.js">
<link rel="modulepreload" href="../../../_npm/d3-shape@3.2.0/6d3a6726.js">
<link rel="modulepreload" href="../../../_npm/d3-time@3.1.0/9f03c579.js">
<link rel="modulepreload" href="../../../_npm/d3-time-format@4.1.0/07c9626f.js">
<link rel="modulepreload" href="../../../_npm/d3-timer@3.0.1/b58a267d.js">
<link rel="modulepreload" href="../../../_npm/d3-transition@3.0.1/004da2ac.js">
<link rel="modulepreload" href="../../../_npm/d3-zoom@3.0.0/b5786b3f.js">
<link rel="modulepreload" href="../../../_npm/tslib@2.8.1/b62a9c4a.js">
<link rel="modulepreload" href="../../../_npm/flatbuffers@25.9.23/c82700c2.js">
<link rel="modulepreload" href="../../../_npm/binary-search-bounds@2.0.5/cbf6ba23.js">
<link rel="modulepreload" href="../../../_npm/internmap@2.0.3/e08981d9.js">
<link rel="modulepreload" href="../../../_npm/delaunator@5.0.1/02d43215.js">
<link rel="modulepreload" href="../../../_npm/robust-predicates@3.0.2/aa00730b.js">
<script type="module">

import {define} from "../../../_observablehq/client.cbf2d9f3.js";
import {registerFile} from "../../../_observablehq/stdlib.43270668.js";

registerFile("../../../data/raw/benchmarks/gpu_comp_history.parquet", {"name":"../../../data/raw/benchmarks/gpu_comp_history.parquet","path":"../../../_file/data/raw/benchmarks/gpu_comp_history.e18efbee.parquet","lastModified":1771468210889,"size":1389327});
registerFile("../../../data/raw/benchmarks/gpu_comp_main.parquet", {"name":"../../../data/raw/benchmarks/gpu_comp_main.parquet","path":"../../../_file/data/raw/benchmarks/gpu_comp_main.d82fa693.parquet","lastModified":1771466904217,"size":21863});
registerFile("../../../data/raw/benchmarks/micro_benchmarks_20260126_130256.json", {"name":"../../../data/raw/benchmarks/micro_benchmarks_20260126_130256.json","mimeType":"application/json","path":"../../../_file/data/raw/benchmarks/micro_benchmarks_20260126_130256.0003d6fe.json","lastModified":1771465633680,"size":2403});
registerFile("../../../data/raw/benchmarks/mps_comp_history.parquet", {"name":"../../../data/raw/benchmarks/mps_comp_history.parquet","path":"../../../_file/data/raw/benchmarks/mps_comp_history.8ee202e9.parquet","lastModified":1771468209776,"size":1535334});
registerFile("../../../data/raw/benchmarks/mps_comp_main.parquet", {"name":"../../../data/raw/benchmarks/mps_comp_main.parquet","path":"../../../_file/data/raw/benchmarks/mps_comp_main.f7579557.parquet","lastModified":1771466904241,"size":21062});
registerFile("../../../data/raw/benchmarks/train_benchmark_20260127_092323.json", {"name":"../../../data/raw/benchmarks/train_benchmark_20260127_092323.json","mimeType":"application/json","path":"../../../_file/data/raw/benchmarks/train_benchmark_20260127_092323.e80aa474.json","lastModified":1771465633684,"size":1945563});
registerFile("../../../data/raw/llm-fundamentals/model-config-catalog.json", {"name":"../../../data/raw/llm-fundamentals/model-config-catalog.json","mimeType":"application/json","path":"../../../_file/data/raw/llm-fundamentals/model-config-catalog.3b260981.json","lastModified":1771314318102,"size":18447});

define({id: "e9422d4d", mode: "inline", inputs: ["tex","display"], body: async (tex,display) => {
display(await(
tex`B`
))
}});

define({id: "292babb6", mode: "inline", inputs: ["tex","display"], body: async (tex,display) => {
display(await(
tex`S`
))
}});

define({id: "d4a5728a", mode: "inline", inputs: ["tex","display"], body: async (tex,display) => {
display(await(
tex`d_{model}`
))
}});

define({id: "276a7cec", mode: "inline", inputs: ["tex","display"], body: async (tex,display) => {
display(await(
tex`d_k`
))
}});

define({id: "de8b04bb", mode: "inline", inputs: ["tex","display"], body: async (tex,display) => {
display(await(
tex`h`
))
}});

define({id: "ae05f8da", mode: "inline", inputs: ["tex","display"], body: async (tex,display) => {
display(await(
tex`h = d_{model} / d_k`
))
}});

define({id: "256dca58", mode: "inline", inputs: ["tex","display"], body: async (tex,display) => {
display(await(
tex`L`
))
}});

define({id: "f3dc34f5", mode: "inline", inputs: ["tex","display"], body: async (tex,display) => {
display(await(
tex`d_{ff}`
))
}});

define({id: "009ce9a3", outputs: ["renderPerfEmpiricalTrainBenchmark","renderPerfEmpiricalExpectedVsActual","renderPerfEmpiricalDeviceComparison","renderPerfEmpiricalModelSelection","renderPerfEmpiricalTrainingCurves"], body: async () => {
const {renderPerfEmpiricalTrainBenchmark, renderPerfEmpiricalExpectedVsActual, renderPerfEmpiricalDeviceComparison, renderPerfEmpiricalModelSelection, renderPerfEmpiricalTrainingCurves} = await import("../../../_import/embed/perf-empirical.afc56bfd.js");

return {renderPerfEmpiricalTrainBenchmark,renderPerfEmpiricalExpectedVsActual,renderPerfEmpiricalDeviceComparison,renderPerfEmpiricalModelSelection,renderPerfEmpiricalTrainingCurves};
}});

define({id: "5f0c9453", inputs: ["renderPerfEmpiricalTrainBenchmark"], outputs: ["trainSection"], body: async (renderPerfEmpiricalTrainBenchmark) => {
const trainSection = await renderPerfEmpiricalTrainBenchmark();
return {trainSection};
}});

define({id: "03091ea1", inputs: ["display","trainSection"], body: (display,trainSection) => {
display(trainSection);
}});

define({id: "d4a5728a-1", mode: "inline", inputs: ["tex","display"], body: async (tex,display) => {
display(await(
tex`d_{model}`
))
}});

define({id: "8664f8c5", mode: "inline", inputs: ["tex","display"], body: async (tex,display) => {
display(await(
tex`S^2`
))
}});

define({id: "78359219", inputs: ["renderPerfEmpiricalExpectedVsActual"], outputs: ["evaSection"], body: async (renderPerfEmpiricalExpectedVsActual) => {
const evaSection = await renderPerfEmpiricalExpectedVsActual();
return {evaSection};
}});

define({id: "100de579", inputs: ["display","evaSection"], body: (display,evaSection) => {
display(evaSection);
}});

define({id: "e95b81ae", inputs: ["renderPerfEmpiricalModelSelection"], outputs: ["modelSelectionSection"], body: async (renderPerfEmpiricalModelSelection) => {
const modelSelectionSection = await renderPerfEmpiricalModelSelection();
return {modelSelectionSection};
}});

define({id: "34c11cd3", inputs: ["display","modelSelectionSection"], body: (display,modelSelectionSection) => {
display(modelSelectionSection);
}});

define({id: "67bfe76d", inputs: ["renderPerfEmpiricalDeviceComparison"], outputs: ["compSection"], body: async (renderPerfEmpiricalDeviceComparison) => {
const compSection = await renderPerfEmpiricalDeviceComparison();
return {compSection};
}});

define({id: "9996ac78", inputs: ["display","compSection"], body: (display,compSection) => {
display(compSection);
}});

define({id: "9dd16f38", inputs: ["renderPerfEmpiricalTrainingCurves"], outputs: ["curvesSection"], body: async (renderPerfEmpiricalTrainingCurves) => {
const curvesSection = await renderPerfEmpiricalTrainingCurves();
return {curvesSection};
}});

define({id: "9924402b", inputs: ["display","curvesSection"], body: (display,curvesSection) => {
display(curvesSection);
}});

</script>
</head>
<body>
<input id="observablehq-sidebar-toggle" type="checkbox" title="Toggle sidebar">
<label id="observablehq-sidebar-backdrop" for="observablehq-sidebar-toggle"></label>
<nav id="observablehq-sidebar">
  <ol>
    <label id="observablehq-sidebar-close" for="observablehq-sidebar-toggle"></label>
    <li class="observablehq-link"><a href="../../../">Project Writeup Sandbox</a></li>
  </ol>
  <ol>
    <li class="observablehq-link"><a href="../../">Projects</a></li>
    <li class="observablehq-link"><a href="../">LLM Fundamentals</a></li>
    <li class="observablehq-link"><a href="../../data-playground/">Data Playground</a></li>
  </ol>
</nav>
<script>{const e=document.querySelector("#observablehq-sidebar"),o=document.querySelector("#observablehq-sidebar-toggle"),r=sessionStorage.getItem("observablehq-sidebar");r?o.checked=r==="true":o.indeterminate=!0;for(const t of document.querySelectorAll("#observablehq-sidebar summary")){const s=t.parentElement;switch(sessionStorage.getItem(`observablehq-sidebar:${t.textContent}`)){case"true":s.open=!0;break;case"false":s.classList.contains("observablehq-section-active")||(s.open=!1);break}}addEventListener("beforeunload",()=>sessionStorage.setItem("observablehq-sidebar-scrolly",`${e.scrollTop}`));const a=sessionStorage.getItem("observablehq-sidebar-scrolly");a!=null&&(e.style.cssText="overflow: hidden;",e.scrollTop=+a,e.style.cssText="");}</script>
<div id="observablehq-center">
<header id="observablehq-header">
<nav class="portfolio-top-links"><a class="portfolio-nav-link" href="../../../" onclick="event.preventDefault(); window.location.assign(window.location.origin + '/');">Home</a><a class="portfolio-nav-link" href="../../" onclick="event.preventDefault(); const mount = window.location.pathname.startsWith('/observable/') ? '/observable' : ''; window.location.assign(window.location.origin + mount + '/projects/');">Projects</a><details id="portfolio-current-project-menu" class="portfolio-project-menu"><summary class="portfolio-nav-link portfolio-project-toggle">LLM Fundamentals</summary><div class="portfolio-project-dropdown"><a class="portfolio-project-item" href="../" onclick="event.preventDefault(); const mount = window.location.pathname.startsWith('/observable/') ? '/observable' : ''; window.location.assign(window.location.origin + mount + '/projects/llm-fundamentals/');">Introduction</a><a class="portfolio-project-item" href="../perf-expected/" onclick="event.preventDefault(); const mount = window.location.pathname.startsWith('/observable/') ? '/observable' : ''; window.location.assign(window.location.origin + mount + '/projects/llm-fundamentals/perf-expected/');">Architecture and Expected Performance Analysis</a><a class="portfolio-project-item" href="./" onclick="event.preventDefault(); const mount = window.location.pathname.startsWith('/observable/') ? '/observable' : ''; window.location.assign(window.location.origin + mount + '/projects/llm-fundamentals/perf-empirical/');">Benchmarks and Empirical Performance Analysis</a><a class="portfolio-project-item" href="../nsys/" onclick="event.preventDefault(); const mount = window.location.pathname.startsWith('/observable/') ? '/observable' : ''; window.location.assign(window.location.origin + mount + '/projects/llm-fundamentals/nsys/');">Nvidia CUDA Nsys Trace Analysis</a><a class="portfolio-project-item" href="../lr-sweep/" onclick="event.preventDefault(); const mount = window.location.pathname.startsWith('/observable/') ? '/observable' : ''; window.location.assign(window.location.origin + mount + '/projects/llm-fundamentals/lr-sweep/');">Learning Parameter Sweeps</a><a class="portfolio-project-item" href="../ablations/" onclick="event.preventDefault(); const mount = window.location.pathname.startsWith('/observable/') ? '/observable' : ''; window.location.assign(window.location.origin + mount + '/projects/llm-fundamentals/ablations/');">Architectural Variations (Ablations)</a></div></details></nav><script>(function(){const path=window.location.pathname.replace(/^\/observable(?=\/|$)/,""); const menu=document.getElementById("portfolio-current-project-menu"); if(menu && /^\/projects\/?$/.test(path)){menu.remove();} if(menu){document.addEventListener("click",(event)=>{if(!menu.hasAttribute("open")) return; if(!menu.contains(event.target)) menu.removeAttribute("open");}); document.addEventListener("keydown",(event)=>{if(event.key==="Escape") menu.removeAttribute("open");});} for(const id of ["observablehq-sidebar-toggle","observablehq-sidebar-backdrop","observablehq-sidebar"]){const node=document.getElementById(id); if(node) node.remove();}})();</script>
</header>
<aside id="observablehq-toc" data-selector="h1:not(:first-of-type)[id], h2:first-child[id], :not(h1) + h2[id]">
<nav>
<div>Contents</div>
<ol>
<li class="observablehq-secondary-link"><a href="#benchmark-grid-search">Benchmark Grid Search</a></li>
<li class="observablehq-secondary-link"><a href="#model-selection">Model Selection</a></li>
<li class="observablehq-secondary-link"><a href="#training-dyanmics-across-architectures">Training Dyanmics Across Architectures</a></li>
<li class="observablehq-secondary-link"><a href="#training-curve-analysis">Training Curve Analysis</a></li>
<li class="observablehq-secondary-link"><a href="#conclusions-1">Conclusions</a></li>
</ol>
</nav>
</aside>
<main id="observablehq-main" class="observablehq">
<h1 id="benchmarks-and-empirical-performance-analysis" tabindex="-1"><a class="observablehq-header-anchor" href="#benchmarks-and-empirical-performance-analysis">Benchmarks and Empirical Performance Analysis</a></h1>
<h2 id="introduction" tabindex="-1"><a class="observablehq-header-anchor" href="#introduction">Introduction</a></h2>
<p>Benchmarking work in this project was centered around pedagogic goals, which were twofold.  First, was simply gaining familiarity with benchmarking tools.  To this end, the PyTorch <code>blocked_autorange</code> method from the <code>benchmark.Timer</code> class was initially used to execute a controlled, large-scale grid search across core model parameters (see below).</p>
<p>These results were then used to generate more robustly estimate model specifications that could be run on the avialable hardware, culminating in two model settings being selected for comparison, one "wide" and another "deep", a relativley standard kind of comparison.  These two models had similar numbers of parameters and compute budgets, but differed on memory use.</p>
<p>After training on the Apple M4, the two models were then trained on the RTX 4090.  This analysis concludes with a comparison of training performance between these two systems, after which we provide sample output from the final model weights.</p>
<h2 id="benchmark-grid-search" tabindex="-1"><a class="observablehq-header-anchor" href="#benchmark-grid-search">Benchmark Grid Search</a></h2>
<p>The first step in benchmarking was a grid search across core models parameters, including</p>
<ul>
<li>bach size <observablehq-loading></observablehq-loading><!--:e9422d4d:--></li>
<li>sequence length <observablehq-loading></observablehq-loading><!--:292babb6:--></li>
<li>model dimension <observablehq-loading></observablehq-loading><!--:d4a5728a:--></li>
<li>head dimension <observablehq-loading></observablehq-loading><!--:276a7cec:--> or number of heads <observablehq-loading></observablehq-loading><!--:de8b04bb:--> (with <observablehq-loading></observablehq-loading><!--:ae05f8da:-->, and locked to multiples of 32)</li>
<li>number of layers/blocks <observablehq-loading></observablehq-loading><!--:256dca58:--></li>
<li>SwiGLU network feedforward dimension <observablehq-loading></observablehq-loading><!--:f3dc34f5:--></li>
</ul>
<p>As the <code>benchmark.Timer</code> class primarily measures time and throughput, those are the metrics collected.  The <code>blocked_autorange</code> method was used on a single training loop iteration, with the expectation that this would result in reliable and repeatable results.  While this is true in the sense that the method does ensure that the memory space is clean and that the device has been synchronized, part of the method's reliability comes from the repeated execution of the code under study, and in this case the minimum time allotted was often lower than the time of a single run.  Nonetheless, the data were consistent with expectations, as can be seen below.</p>
<div class="observablehq observablehq--block"><!--:009ce9a3:--></div>
<div class="observablehq observablehq--block"><!--:5f0c9453:--></div>
<div class="observablehq observablehq--block"><!--:03091ea1:--></div>
<h4 id="observations" tabindex="-1"><a class="observablehq-header-anchor" href="#observations">Observations</a></h4>
<ul>
<li>smaller <observablehq-loading></observablehq-loading><!--:d4a5728a-1:--> lead to higher tokens/sec</li>
<li>larger sequence lengths quickly exceed memory capacity due to the attention's <observablehq-loading></observablehq-loading><!--:8664f8c5:--> scaling</li>
<li>in practice, this chart was useful for finding interesting and less-controlled comparison models, as batch size can be varied along with other parameters to find diverse models that have similar training memory budgets</li>
</ul>
<h3 id="expected-vs-actual-performance" tabindex="-1"><a class="observablehq-header-anchor" href="#expected-vs-actual-performance">Expected vs Actual Performance</a></h3>
<p>It's important to note that these are "expected" in the sense of "calculated based on listed system TFLOPs" rather than any more nuanced estimation.  As such, performance is always worse than "expected", with the dashed line on the following charts reflecting the point where actual and expected would have been equal.</p>
<div class="observablehq observablehq--block"><!--:78359219:--></div>
<div class="observablehq observablehq--block"><!--:100de579:--></div>
<h4 id="observations-1" tabindex="-1"><a class="observablehq-header-anchor" href="#observations-1">Observations</a></h4>
<ul>
<li>larger models display nonlinear slowdowns, suggesting the expected effect of memory bottlenecking does occur</li>
<li>even more significant memory issues arise in large models, which see an explosive growth in observed iteration time when the system becomes stressed</li>
<li>increased batch size does in fact show increased training throughput, validating the hypothesis that kenrel launches are an additional bottleneck on MPS</li>
</ul>
<h3 id="conclusions" tabindex="-1"><a class="observablehq-header-anchor" href="#conclusions">Conclusions</a></h3>
<p>The observations broadly reflects expectations.  The modifier "broadly" is used because there is a persistent level of uncertainty associated with Apple Silicon and the MacOS/MPS: first, and that even with the controls of the PyTorch benchmark library, the Mac is operating as a desktop system, and has numerous processes that can lead to resource contention unpredictably.  We did leave the system to run these benchmarks overnight, turned off backups, and closed all apps, so the data emerged relatively clean.</p>
<p>Returning to core questions of traning dynamics, the main question based on research into the system is whether it is heavily memory-bottlenecked preventing larger models from being trained, or does it suffers from a poorly optimized stack that requires numerous MPS kernel launces, increasing overhead and causing increased batch size to</p>
<p>In fact both are true, so increasing batch size does lead to improved throughput, while larger models do bog down the system and show increasingly sub-optimal performance.</p>
<h2 id="model-selection" tabindex="-1"><a class="observablehq-header-anchor" href="#model-selection">Model Selection</a></h2>
<p>Ultimately, in order to provide a robust comparison while remaining within memory limits, two model specs were chosen, one of which was actually outside the grid seach as its width made the feasible number of layers smaller than the minimum in the grid.</p>
<div class="observablehq observablehq--block"><!--:e95b81ae:--></div>
<div class="observablehq observablehq--block"><!--:34c11cd3:--></div>
<p>The decision to use these models was reached after an attempt at training larger models took excessive time.  Those models were also varying across a variety of parameters, which is interesting for a more intuitive approach to research, but a more controlled "deep vs wide" comparison is more appropriate for this project.</p>
<p>So the two models selected were matched on many parameters, with the choice made to keep head count equal and change the head dimension, as well as model and feedforward dimensions.  To compensate for the differnce in width, the model size estimator was used to select a number of layers for the widemodel that would result in an equivalent parameter count.</p>
<p>Overall model training memory could have been more controlled with the use of gradient checkpointing during training, which would have significantly alleviated the memory consumption caused by tracking activation values across many layers, however this was not part of the assignment spec and the models were sized to fit comfortably in system memory, making this unnecessary.</p>
<p>Based on existing literature, it was expected that model A would converge to its minimum loss more quickly due to having fewer layers, but would also probably have a higher minimum loss as the architecture can only learn a relatively flat manifold. for the same reason.</p>
<h2 id="training-dyanmics-across-architectures" tabindex="-1"><a class="observablehq-header-anchor" href="#training-dyanmics-across-architectures">Training Dyanmics Across Architectures</a></h2>
<h3 id="training-throughput-comparison" tabindex="-1"><a class="observablehq-header-anchor" href="#training-throughput-comparison">Training Throughput Comparison</a></h3>
<p>As expected, the RTS 4090 showed a significant speedup of about 20x for the wide model A, and 16x for the deep model B.  This is suprirsingly close to the 20x speedup expected for float32 operations on the RTX, with the reduced performance in the deep model likely caused by memory latency.</p>
<div class="observablehq observablehq--block"><!--:67bfe76d:--></div>
<div class="observablehq observablehq--block"><!--:9996ac78:--></div>
<p>Interestingly, the iteration times for the deep model on MPS show a period of increased step time, probably due to MacOS housekeeping that was triggered automatically.  This could be a memory management artifact, as there are additional latency spikes, probably due to memory pressure, even though the model on paper should fit comfortably.</p>
<h2 id="training-curve-analysis" tabindex="-1"><a class="observablehq-header-anchor" href="#training-curve-analysis">Training Curve Analysis</a></h2>
<div class="observablehq observablehq--block"><!--:9dd16f38:--></div>
<div class="observablehq observablehq--block"><!--:9924402b:--></div>
<p>Training shows the expected dynamics, where the wide model A converges more quickly but to a higher steady-state loss, while the deep model B converges more slowly to lower steady state.  The pre-clipping gradient norm is consistent with this dynamic, with the norm for the deep model remaining elevated for about 20 cycles longer than the wide model.</p>
<h2 id="conclusions-1" tabindex="-1"><a class="observablehq-header-anchor" href="#conclusions-1">Conclusions</a></h2>
<p>Overall, this investigation successfully highlighted the practical constraints and trade-offs in LLM training. The hardware comparison showed a clear advantage for the RTX 4090, which delivered a consistent ~20x speedup over the Apple M4, effectively matching theoretical expectations for float32 performance. While the M4 was certainly functional for smaller-scale experimentation, the analysis also highlighted its susceptibility to memory management latency and kernel launch overheads, particularly with deeper network architectures.</p>
<p>On the architectural front, the controlled comparison between "wide" and "deep" models confirmed established intuitions: the wider, shallower model offered rapid convergence but limited capacity, while the deeper model achieved a lower steady-state loss at the cost of longer training horizons. Taken together, these results show that while consumer silicon can support initial development, scaling model depth and performance requires both specialized hardware and careful architectural tuning.</p>
</main>
<footer id="observablehq-footer">
<div>Built with <a href="https://observablehq.com/" target="_blank" rel="noopener noreferrer">Observable</a> on <a title="2026-02-19T15:57:04">Feb 19, 2026</a>.</div>
</footer>
</div>
</body>
</html>
